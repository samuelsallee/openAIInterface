{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the dataset\n",
    "\n",
    "The dataset used in this example is [fine-food reviews](https://www.kaggle.com/snap/amazon-fine-food-reviews) from Amazon. The dataset contains a total of 568,454 food reviews Amazon users left up to October 2012. We will use a subset of this dataset, consisting of 1,000 most recent reviews for illustration purposes. The reviews are in English and tend to be positive or negative. Each review has a ProductId, UserId, Score, review title (Summary) and review body (Text).\n",
    "\n",
    "We will combine the review summary and review text into a single combined text. The model will encode this combined text and it will output a single vector embedding."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this notebook, you will need to install: pandas, openai, transformers, plotly, matplotlib, scikit-learn, torch (transformer dep), torchvision, and scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215972"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd, tltk, cld3, openai\n",
    "import tiktoken\n",
    "from openai.embeddings_utils import get_embedding\n",
    "215972"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding model parameters\n",
    "openai.api_key = \"put_api_key_here\"\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "embedding_encoding = \"cl100k_base\"  # this the encoding for text-embedding-ada-002\n",
    "max_tokens = 8000  # the maximum for text-embedding-ada-002 is 8191\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pr_engname</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cprcode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225407</th>\n",
       "      <td>KONJAC LINGUINI</td>\n",
       "      <td>Title: KONJAC LINGUINI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241101</th>\n",
       "      <td>BUMILGOCHUJANG</td>\n",
       "      <td>Title: BUMILGOCHUJANG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pr_engname                combined\n",
       "cprcode                                         \n",
       "225407   KONJAC LINGUINI  Title: KONJAC LINGUINI\n",
       "241101    BUMILGOCHUJANG   Title: BUMILGOCHUJANG"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load & inspect dataset\n",
    "input_datapath = \"dynamodb_export.csv\"  # to save space, we provide a pre-filtered dataset\n",
    "df = pd.read_csv(input_datapath, index_col=0)\n",
    "print()\n",
    "df = df[[\"pr_engname\"]]\n",
    "# df = df[[\"Time\", \"ProductId\", \"UserId\", \"Score\", \"Summary\", \"Text\"]]\n",
    "df = df.dropna()\n",
    "df[\"combined\"] = (\n",
    "    \"Title: \" + df.pr_engname.str.strip()\n",
    ")\n",
    "df.head(2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertThaiToRoman(word):\n",
    "    j = 0\n",
    "    try:\n",
    "        lastIndex = 0\n",
    "        startString = \"\"\n",
    "        currentlyThai = cld3.get_language(word[:2])[0] == \"th\"\n",
    "\n",
    "        while j < len(word):\n",
    "\n",
    "            if word[j] >= '0' and word[j] <= '9' or word[j] == \" \":\n",
    "                # print(\"num\", end=\" \")\n",
    "                if currentlyThai:\n",
    "                    startString = startString + tltk.nlp.th2roman(word[lastIndex:j])\n",
    "                else:\n",
    "                    startString = startString + word[lastIndex:j]\n",
    "                currentlyThai = False\n",
    "\n",
    "                # if j - lastIndex > 1:\n",
    "                #     if currentlyThai:\n",
    "                #         startString = startString + tltk.nlp.th2roman(word[lastIndex:j])\n",
    "                #     else:\n",
    "                #         startString = startString + word[lastIndex:j]\n",
    "                # else:\n",
    "                #     startString = startString + word[j]\n",
    "                # lastIndex = j\n",
    "\n",
    "            elif cld3.get_language(word[j])[0] == 'th' and currentlyThai == False:\n",
    "                currentlyThai = True\n",
    "                startString = startString + word[lastIndex:j]\n",
    "                lastIndex = j\n",
    "            \n",
    "            elif cld3.get_language(word[j])[0] != 'th' and word[j] != \" \" and currentlyThai == True:\n",
    "                currentlyThai = False\n",
    "                startString = startString + tltk.nlp.th2roman(word[lastIndex:j])\n",
    "                lastIndex = j\n",
    "            j += 1\n",
    "        if currentlyThai:\n",
    "            startString = startString + tltk.nlp.th2roman(word[lastIndex:])\n",
    "        else:\n",
    "            startString = startString + word[lastIndex:]\n",
    "        startString = startString.replace(\"<s/>\", \"\")\n",
    "        returnStr = \"\"\n",
    "        lastIndex = 0\n",
    "        for i in range(len(startString)):\n",
    "            if ord(startString[i]) > 256:\n",
    "                returnStr = returnStr + startString[lastIndex:i]\n",
    "                lastIndex = i+1\n",
    "                i += 1\n",
    "        return returnStr + startString[lastIndex:]\n",
    "    except Exception as e:\n",
    "        print(word, \" j=\", j, word[j])\n",
    "\n",
    "\n",
    "\n",
    "df.pr_engname = df.pr_engname.apply(lambda x: convertThaiToRoman(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'namta lo duan klong '"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertThaiToRoman(\"น้ำตาลอิดวลกล่อง\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namta lo duan klong \n"
     ]
    }
   ],
   "source": [
    "# for i in df.index:\n",
    "print(df.pr_engname[215972])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subsample to 1k most recent reviews and remove samples that are too long\n",
    "top_n = 1000\n",
    "# df = df.sort_values(\"Time\").tail(top_n * 2)  # first cut to first 2k entries, assuming less than half will be filtered out\n",
    "# df.drop(\"Time\", axis=1, inplace=True)\n",
    "\n",
    "encoding = tiktoken.get_encoding(embedding_encoding)\n",
    "\n",
    "# omit reviews that are too long to embed\n",
    "df[\"n_tokens\"] = df.pr_engname.apply(lambda x: len(encoding.encode(x)))\n",
    "df = df[df.n_tokens <= max_tokens].tail(top_n)\n",
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.pr_engname)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get embeddings and save them for future reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def th_to_eng_plus_embedding(input_text):\n",
    "    print(input_text)\n",
    "    x = tltk.nlp.th2roman(input_text)\n",
    "    print(x)\n",
    "    return get_embedding(x, engine=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you have your API key set in your environment per the README: https://github.com/openai/openai-python#usage\n",
    "\n",
    "# This may take a few minutes\n",
    "df[\"embedding\"] = df.pr_engname.apply(lambda x: get_embedding(x, engine=embedding_model))\n",
    "df.to_csv(\"villa_database_small_with_embeddings.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cprcode\n",
       "225407    [0.0059991516172885895, 0.01071902271360159, 0...\n",
       "241101    [-0.009435143321752548, -0.00780933303758502, ...\n",
       "190100    [-0.0004730912041850388, -0.015635056421160698...\n",
       "62644     [-0.009714074432849884, -0.011211106553673744,...\n",
       "192167    [0.0028642520774155855, 0.011631874367594719, ...\n",
       "                                ...                        \n",
       "51346     [-0.023128684610128403, -0.00698480848222971, ...\n",
       "171600    [0.0011257551377639174, -0.010720201767981052,...\n",
       "236423    [-0.009764665737748146, -0.017009418457746506,...\n",
       "85473     [-0.0010519151110202074, -0.033062975853681564...\n",
       "209365    [-0.01668184995651245, -0.014079852029681206, ...\n",
       "Name: embedding, Length: 363, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3621"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord(\"ล\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python39",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
